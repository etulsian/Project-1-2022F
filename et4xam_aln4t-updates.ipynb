{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Assembling Genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   <div class=\"alert alert-block alert-danger\">\n",
    "    <center>Due: <b>Monday, September 5, 8:59pm</b>.</center> \n",
    "   </div>\n",
    "   \n",
    "   <div class=\"alert alert-block alert-warning\">\n",
    "   <center>\n",
    "       <b>Collaboration and Resource Policy</b>\n",
    "    </center>\n",
    "    \n",
    "For this assignment, you are encouraged to work with one other person satisfying the constraints from Class 2. \n",
    "You are permitted (actually _encouraged_) to discuss these problems with anyone you want, including other students in the class. If you do discuss the specific questions in the assignment with anyone other than your assignment partner and the course staff, though, you should list them in the _External resources used_ section below.\n",
    "    \n",
    "You are welcome to use any resources you want for this assignment, other than ones that would defeat the purpose of the assignment. This means you should not look at answers or code from previous semesters of this course, or from any other students in the class (other than your collaboration with your partner), and if you find code that implements the problem you are being asked to do for the assignment, you should not use that code. You should document all external resource you use that are not part of the course materials in the _External resources used_ section below.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team submitting this assignment:**  \n",
    "<div class=\"alert alert-success\">\n",
    "    <b><em>list each member of your team here, including both your name and UVA computing id</em></b>\n",
    "\n",
    "Team Members (Names): Esha Tulsian and Amelia Norman \n",
    "\n",
    "Team Member UVA Computing IDs: et4xam and aln4t\n",
    "\n",
    "</div>\n",
    "\n",
    "**External resources used:** \n",
    "<div class=\"alert alert-success\">\n",
    "<em>It is not necessary to list the course materials, but if you used any other resources, including discussing problems with students not on your team, list them here.</em>\n",
    "    \n",
    "External Resources Used:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will explore genome assemblyâ€”the process of determining the order of nucleotides in DNA from fragmented reads. As you might have studied in the reading assignments, genome assembly can get quite complicated, as problems such as full sequence coverage, finding a good length for reads (the $k$ in $k$-mer), and sequencing errors present challenges for sequencing analysis and accuracy. You can assume perfect coverage for all parts of the assignment and no read errors for the first two questions.\n",
    "\n",
    "\n",
    "<b>Submission</b>: Please submit the code you wrote to generate your answers for all parts using this form: <a href=\"https://forms.gle/rNTXfYojTLEQ8idg6\"><em>https://forms.gle/rNTXfYojTLEQ8idg6</em></a>. Your answers should be in the Jupyter Notebook, along with your code. Before submission, you should make a copy of your notebook file with the name <i>uvaid1\\_uvaid2.ipynb</i> (where <i>uvaidn</i> is each teammates UVA id) so the submitted file identifies you. You and your partner should submit a single file once together. Submission is due 8:59 pm (EST) on Monday, September 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install basic required packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Install basic required packages, should be run only once. You may need to restart the kernel after this stage.\n",
    "- Make sure you have [graphviz](https://graphviz.org/download/) installed on your system.\n",
    "- The second cell adds Graphviz to your path, you may have to change based on where the install folder is.\n",
    "\n",
    "<b>NOTE: We provide utils.py, which may contain helpful functions for you to use, as well as gvmagic.py, which is a deprecated package to use graphviz within the notebook</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\etuls\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (1.18.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\etuls\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (3.2.2)\n",
      "Requirement already satisfied: pydot in c:\\users\\etuls\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\etuls\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (0.20.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\etuls\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\etuls\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\etuls\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\etuls\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\etuls\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 2)) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 2,
=======
   "execution_count": 1,
   "id": "0ca4b350",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genome Assembly\n",
    "\n",
    "For this part, you're given reads generated while trying to sequence the DNA of a TeleTubby (some unknown organism) with a \\textit{very} small genetic code. By answering the following questions, you will learn how to assemble the original genome sequence from sequence reads.\n",
    "\n",
    "Sequencing data is often stored in FASTQ file format. In TeleTubby.fastq, you will find the data organized in a particular order that repeats every four lines. The first line contains the metadata that encodes the name of the read, the experiment type, the kind of sequencing machine used, etc. The second line is the sequence of bases. The third line functions as a placeholder line. The fourth line is a sequence of base qualities that encode the qualities for the corresponding bases in the sequence line. We will only work with the sequence and quality score lines in this question."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 3,
=======
   "execution_count": 2,
   "id": "8dfcf02a",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utils\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.1.1 GC-content\n",
    "\n",
    "The GC-content (or the ratio of G and C nucleotides) is related to the melting temperature of the DNA double helix. Use the following equation to calculate the melting temperature of DNA for TeleTubby $t_m$ in Celsius:\n",
    "\n",
    "\\begin{equation*}\n",
    "t_m = 64.9+0.41(\\%GC)-\\frac{500}{\\text{length of sequence}}\n",
    "\\end{equation*}\n",
    "\n",
    "As a reference, the human genome is known to have between 35%-60% GC-content. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 4,
=======
   "execution_count": 3,
   "id": "283afc60",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sequence reads (error-free) from file\n",
    "sequence_reads, qualities = utils.read_fastq('TeleTubby.fastq')\n",
    "tot = len(sequence_reads)\n",
    "\n",
    "# Find total pairs\n",
    "sequences = tot * 8\n",
    "# Find individual pair values\n",
    "vals = []\n",
    "for i in range(tot):   # adds chars from genome to vals\n",
    "    temp = list(sequence_reads[i])\n",
    "    for j in temp:\n",
    "        vals.append(j)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 5,
=======
   "execution_count": 4,
   "id": "44c030ab",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find # of C--G pairs\n",
    "count = 0\n",
    "for i in range(sequences):\n",
    "    if vals[i] == 'C' or vals[i] == 'G':\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 6,
=======
   "execution_count": 5,
   "id": "462e8a41",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.95221843003413\n"
     ]
    }
   ],
   "source": [
    "# Calculate %GC content\n",
    "GC_pct = (count/sequences) * 100   # ASK: should this be a decimal or whole number?\n",
    "print(GC_pct)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 7,
=======
   "execution_count": 6,
   "id": "13ac280b",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.34709897610922\n"
     ]
    }
   ],
   "source": [
    "# Print out temperature in Celsius\n",
    "temp_tt = 64.9 + (0.41*GC_pct) - (500/sequences)\n",
    "print(temp_tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.1.2 Interpreting quality scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phred33 quality scores are represented as the character with an ASCII code equal to its value + 33 (to make them easy to print alongside genome sequences). List the top 5 most frequent scores in ASCII symbol as well as their Phredd33 scores in TeleTubby.fastq. You can refer to the [official Illumina website](https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm) to reference the scoring encoding.\n",
    "\n",
    "What is the average Phred33 score in TeleTubby.fastq?"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 8,
=======
   "execution_count": 7,
   "id": "f22ec36e",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate vals\n",
    "scores = []\n",
    "for i in range(tot):   # adds chars from genome to vals\n",
    "    temp = list(qualities[i])\n",
    "    for j in temp:\n",
    "        scores.append(j)\n",
    "        \n",
    "scores_df = pd.DataFrame({\"scores\":scores})   # makes it easier to use functions\n",
    "\n",
    "top_5 = scores_df[\"scores\"].value_counts().head(5).index.values   # automatically sorted in descending order\n",
    "top_5 = [top_5[i][0] for i in range(5)]\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 9,
=======
   "execution_count": 8,
   "id": "605a4b6f",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Phred33 score\n",
    "phred33 = []\n",
    "# convert ASCII+33\n",
    "for i in top_5:\n",
    "    phred33.append(ord(i)-33)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 10,
=======
   "execution_count": 9,
   "id": "c03bb737",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASCII</th>\n",
       "      <th>Phred33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>?</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ASCII  Phred33\n",
       "0     5       20\n",
       "1     D       35\n",
       "2     ?       30\n",
       "3     K       42\n",
       "4     F       37"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DF; print ascii and phred33 scores\n",
    "freq_qualities = pd.DataFrame({\"ASCII\":top_5, \"Phred33\":phred33})\n",
    "freq_qualities"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 11,
=======
   "execution_count": 10,
   "id": "1fdce189",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.476535836177476"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average Phred33 scores\n",
    "all_phred33 = []\n",
    "for i in scores:\n",
    "    all_phred33.append(ord(i)-33)\n",
    "mean_phred33 = statistics.mean(all_phred33)\n",
    "mean_phred33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.1.3 Frequency analysis\n",
    "\n",
    "Looking at repetitions in the sequence can be helpful in estimating the \"redudancy\" in the organisms. Humand and other evolved animals have a lot of redundancy, while smaller organisms like bacteria have highly packed genomes. One heuristic to estimate this before actually performing the assembly could be looking at how often certain $k$-mers are repeated.\n",
    "\n",
    "<b>Print out the 3 most frequent k-mers with their frequencies</b>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 12,
=======
   "execution_count": 11,
   "id": "65a1188e",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and print out the three most repeated k-mers and their frequencies\n",
    "def calc_kmers(reads):\n",
    "    sequence_lst = []   # temp storage for finding most common seq\n",
    "    for seq in reads:\n",
    "        for pos in range(8):   # grabbing individual characters\n",
    "            end_pt = 7-pos   # distance to end of string\n",
    "            temp = 1   # determines length of sub-sequence \n",
    "            for i in range(end_pt):\n",
    "                subset = seq[pos:(pos+temp+1)]\n",
    "                sequence_lst.append(subset)\n",
    "                temp += 1\n",
    "    return sequence_lst   # for later calculation of full genome"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 13,
=======
   "execution_count": 12,
   "id": "ec29c1b8",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop list of full genome\n",
    "kmers = calc_kmers(sequence_reads)\n",
    "#print(len(kmers))\n",
    "\n",
    "# check if we have all values calculated (later)\n",
    "#print(28*293)   # num vals we should have"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k-mers</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GC</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TG</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  k-mers  Frequency\n",
       "0     GC        165\n",
       "1     TG        157\n",
       "2     AA        152"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
=======
   "execution_count": 13,
   "id": "15ad5a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 most frequent k-mers and their frequencies:\n",
      "GC    165\n",
      "TG    157\n",
      "CA    152\n",
      "Name: kmers, dtype: int64\n"
     ]
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
    }
   ],
   "source": [
    "# pandas again, for the easy peasy value_counts()\n",
    "all_kmers = pd.DataFrame({\"kmers\":kmers})\n",
    "top_3 = all_kmers[\"kmers\"].value_counts().head(3)\n",
    "top_3_kmers = top_3.index.values\n",
    "top_3_freq = list(top_3)\n",
    "top_kmers = pd.DataFrame({\"k-mers\":top_3_kmers, \"Frequency\":top_3_freq})\n",
    "top_kmers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2. Greedy approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the approaches to assemble the genome from the given reads is a greedy algorithm. Have a look at the greedy algorithm described on [Wikipedia](https://en.wikipedia.org/wiki/Sequence_assembly#Greedy_algorithm) and answer the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.2.1 What would the runtime be of this algorithm, given $n$ $k$-mer reads?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Answer</i>: Assuming we have to sort, then the runtime would be O(N*logN). If not, then the runtime would be O(n)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.2.2 Would this algorithm always yield a unique solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Answer</i>: No, the greedy algorithm looks for the optimal solution at any given moment, but that does not always result in unique solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.2.3 Would this algorithm always yield the <i>right</i> solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Answer</i>: No, this algorithm makes decisions based on the local information present at the moment without taking into account the overall or global problem, so it does not always result in the the global right solution but does choose the local best solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3 Graph-based approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphs for genome assembly can be constructed in two ways:\n",
    "\n",
    "- de Bruijn graph: Processing $k-$mers as nodes, with $(k-1)-$mers as edges, and\n",
    "- Overlap graph: Processing $k-$mers as edges, with $(k-1)-$mers as nodes.\n",
    "\n",
    "de Bruijn graphs can be processed to find Euler paths, while Overlap graphs can be processed to find Hamiltonian paths. Both of these are valid ways to reconstruct the original genome.\n",
    "\n",
    "<b>Use one of these two techniques to reconstruct the sequence, and print out your reconstructed sequence. Which method did you pick out of the two, and why? (hint: imagine what would happen when we have millions of reads). Use the k-mers provided in TeleTubby.fastq</b>.\n",
    "\n",
    "We provide some skeleton code that you may use, but you may also come up with your own solution."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 15,
=======
   "execution_count": 218,
   "id": "71e01e89",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read reads into graph\n",
    "# using de Bruijn graph; \n",
    "# prefix = first 7 (k-1) chars\n",
    "# suffix = last 7 (k-1) chars\n",
    "# if suffix(A) == prefix(B), edge A-->B \n",
    "def buildGraph(k_mers):\n",
    "    edges = []   # edges; kmers\n",
    "    nodes = set()   # create nodes; k-1mers\n",
    "    # find all edges\n",
<<<<<<< HEAD:et4xam_aln4t.ipynb
    "    for seq in k_mers:\n",
    "        suffix = seq[1:]  # calculate suffix \n",
    "        for other in k_mers:\n",
    "            if other != seq: \n",
    "                prefix = other[:7]    # calculate prefix of other k-mers\n",
    "                if suffix == prefix:\n",
    "                    if seq in edges:\n",
    "                        edges[seq].append(other)\n",
    "                    else:\n",
    "                        edges[seq] = [other]\n",
    "    return nodes, edges"
=======
    "    for seq in set(k_mers):   # resolve identical labelling\n",
    "        prefix = seq[:7]\n",
    "        suffix = seq[1:]\n",
    "        edges.append(seq)\n",
    "        nodes.add(prefix)\n",
    "        nodes.add(suffix)\n",
    "    # build graph\n",
    "    graph = {}\n",
    "    for i in edges:\n",
    "        pre = i[:7]\n",
    "        suf = i[1:]\n",
    "        # create directed graph from prefix to suffix\n",
    "        if pre in graph:\n",
    "            graph[pre].append(i)   # creates edge (kmers), which point to next node by calc. suffix\n",
    "        else:\n",
    "            graph[pre] = [i]   # creates edge (kmers), which point to next node by calc. suffix\n",
    "    return graph"
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 16,
=======
   "execution_count": 219,
   "id": "c2e0cee9",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = buildGraph(sequence_reads)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 17,
=======
   "execution_count": 331,
   "id": "81cae372",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "copy_graph = copy.deepcopy(graph)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 18,
=======
   "execution_count": 332,
   "id": "e3dd5a84",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement assembly algorithm; Eulerian path\n",
    "\n",
    "def traverseGraph(node, section=[]):\n",
    "    global copy_graph\n",
    "    if node in copy_graph:\n",
    "        for e in copy_graph[node]:\n",
    "            if len(copy_graph[node]) > 1:\n",
    "                copy_graph[node].remove(e)\n",
    "            else:\n",
    "                del copy_graph[node]\n",
    "            traverseGraph(e[1:], section)\n",
    "    section.insert(0, node)\n",
    "    return section\n",
    "    \n",
    "def eulerianPath(g):\n",
    "    global copy_graph\n",
    "    solution = []\n",
    "    while len(copy_graph) != 0:\n",
    "        #print(len(copy_graph))\n",
    "        new_start = list(copy_graph.keys())[0]   # get an arbitrary start node\n",
    "        sec = traverseGraph(new_start)\n",
    "        solution.append(sec)\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 19,
=======
   "execution_count": 333,
   "id": "8fbec456",
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
<<<<<<< HEAD:et4xam_aln4t.ipynb
    "print(len(copy_edges))\n",
    "eulerianPath(list(copy_edges.keys())[0])\n",
    "print(len(solution), len(nodes)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(copy_edges)   # ALL EDGES TRAVERSED"
=======
    "sol_test = eulerianPath(graph)\n",
    "#len(sol_test)"
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:et4xam_aln4t.ipynb
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could just clean this up, but first check OH for better sol for eulerian path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TTACAAGA', 'TACAAGAA', 'ACAAGAAT', 'CAAGAATT', 'AAGAATTA', 'AGAATTAC', 'GAATTACA', 'AATTACAG', 'ATTACAGG', 'TTACAGGA', 'TACAGGAG', 'ACAGGAGC', 'CAGGAGCC', 'AGGAGCCA', 'GGAGCCAA', 'GAGCCAAA', 'AGCCAAAC', 'GCCAAACA', 'CCAAACAC', 'CAAACACT', 'AAACACTC', 'AACACTCG', 'ACACTCGC', 'CACTCGCT', 'ACTCGCTG', 'CTCGCTGT', 'TCGCTGTC', 'CGCTGTCA', 'GCTGTCAT', 'CTGTCATG', 'TGTCATGG', 'GTCATGGT', 'TCATGGTA', 'CATGGTAT', 'ATGGTATC', 'TGGTATCG', 'GGTATCGA', 'GTATCGAC', 'TATCGACA', 'ATCGACAT', 'TCGACATA', 'CGACATAT', 'GACATATC', 'ACATATCG', 'CATATCGC', 'ATATCGCT', 'TATCGCTG', 'ATCGCTGC', 'TCGCTGCC', 'CGCTGCCC', 'GCTGCCCG', 'CTGCCCGG', 'TGCCCGGA', 'GCCCGGAG', 'CCCGGAGG', 'CCGGAGGC', 'CGGAGGCG', 'GGAGGCGC', 'GAGGCGCT', 'AGGCGCTA', 'GGCGCTAT', 'GCGCTATC', 'CGCTATCG', 'GCTATCGC', 'CTATCGCA', 'TATCGCAA', 'ATCGCAAC', 'TCGCAACC', 'CGCAACCT', 'GCAACCTA', 'CAACCTAA', 'AACCTAAG', 'ACCTAAGA', 'CCTAAGAG', 'CTAAGAGA', 'TAAGAGAG', 'AAGAGAGA', 'AGAGAGAA', 'GAGAGAAG', 'AGAGAAGG', 'GAGAAGGG', 'AGAAGGGG', 'GAAGGGGT', 'AAGGGGTT', 'AGGGGTTT', 'GGGGTTTT', 'GGGTTTTG', 'GGTTTTGT', 'GTTTTGTG', 'TTTTGTGT', 'TTTGTGTT', 'TTGTGTTA', 'TGTGTTAG', 'GTGTTAGC', 'TGTTAGCA', 'GTTAGCAG', 'TTAGCAGT', 'TAGCAGTT', 'AGCAGTTT', 'GCAGTTTC', 'CAGTTTCT', 'AGTTTCTT', 'GTTTCTTC', 'TTTCTTCA', 'TTCTTCAT', 'TCTTCATG', 'CTTCATGC', 'TTCATGCA', 'TCATGCAT', 'CATGCATC', 'ATGCATCT', 'TGCATCTC', 'GCATCTCT', 'CATCTCTT', 'ATCTCTTT', 'TCTCTTTA', 'CTCTTTAC', 'TCTTTACA', 'CTTTACAA', 'TTTACAAG', 'CGGACTCT', 'GGACTCTT', 'GACTCTTT', 'ACTCTTTC', 'CTCTTTCA', 'TCTTTCAT', 'CTTTCATG', 'TTTCATGA', 'TTCATGAG', 'TCATGAGC', 'CATGAGCA', 'ATGAGCAA', 'TGAGCAAA', 'GAGCAAAA', 'AGCAAAAA', 'GCAAAAAA', 'CAAAAAAA', 'AAAAAAAG', 'AAAAAAGT', 'AAAAAGTG', 'AAAAGTGG', 'AAAGTGGG', 'AAGTGGGA', 'AGTGGGAG', 'GTGGGAGT', 'TGGGAGTA', 'GGGAGTAT', 'GGAGTATG', 'GAGTATGG', 'AGTATGGT', 'GTATGGTG', 'TATGGTGC', 'ATGGTGCA', 'TGGTGCAC', 'GGTGCACA', 'GTGCACAT', 'TGCACATC', 'GCACATCC', 'CACATCCG', 'ACATCCGC', 'CATCCGCT', 'ATCCGCTA', 'TCCGCTAT', 'CCGCTATC', 'CGACTGTC', 'GACTGTCG', 'ACTGTCGG', 'CTGTCGGA', 'TGTCGGAC', 'GTCGGACT', 'TCGGACTC', 'CGCAAACC', 'GCAAACCG', 'CAAACCGA', 'AAACCGAC', 'AACCGACT', 'ACCGACTG', 'CCGACTGT', 'CCGCCCTT', 'CGCCCTTC', 'GCCCTTCG', 'CCCTTCGA', 'CCTTCGAT', 'CTTCGATG', 'TTCGATGC', 'TCGATGCA', 'CGATGCAA', 'GATGCAAT', 'ATGCAATG', 'TGCAATGT', 'GCAATGTT', 'TACGCCAA', 'ACGCCAAA', 'CGCCAAAT', 'GCCAAATA', 'CCAAATAG', 'CAAATAGC', 'AAATAGCA', 'AATAGCAA', 'ATAGCAAT', 'TAGCAATG', 'AGCAATGC', 'GCAATGCG', 'CAATGCGC', 'AATGCGCA', 'ATGCGCAG', 'TGCGCAGG', 'GCGCAGGA', 'CGCAGGAT', 'GCAGGATA', 'CAGGATAA', 'AGGATAAC', 'GGATAACA', 'GATAACAA', 'ATAACAAC', 'TAACAACT', 'AACAACTT', 'ACAACTTA', 'CAACTTAT', 'AACTTATG', 'ACTTATGT', 'CTTATGTA', 'TTATGTAC', 'TATGTACT', 'ATGTACTA', 'TGTACTAC', 'GTACTACA', 'TACTACAT', 'ACTACATG', 'CTACATGT', 'TACATGTT', 'ACATGTTG', 'CATGTTGT', 'ATGTTGTT', 'TGTTGTTT', 'GTTGTTTC', 'TTGTTTCT', 'TGTTTCTC', 'GTTTCTCG', 'TTTCTCGT', 'TTCTCGTG', 'TCTCGTGC', 'CTCGTGCC', 'TCGTGCCC', 'CGTGCCCG', 'GTGCCCGC', 'TGCCCGCC', 'GCCCGCCA', 'CCCGCCAA', 'CCGCCAAT', 'CGCCAATG', 'GCCAATGT', 'CCAATGTC', 'CAATGTCG', 'AATGTCGA', 'ATGTCGAG', 'TGTCGAGA', 'GTCGAGAG', 'TCGAGAGA', 'CGAGAGAT', 'GAGAGATT', 'AGAGATTT', 'GAGATTTG', 'AGATTTGT', 'GATTTGTG', 'ATTTGTGC', 'TTTGTGCT', 'TTGTGCTA', 'TGTGCTAT', 'GTGCTATC', 'TGCTATCG', 'TGGTGCCG', 'GGTGCCGC', 'GTGCCGCC', 'TGCCGCCC', 'GCCGCCCT', 'ATCGCTAC', 'TCGCTACT', 'CGCTACTG', 'GCTACTGG', 'CTACTGGT', 'TACTGGTG', 'ACTGGTGC', 'CTGGTGCC', 'ATCGCAAA', 'TCGCAAAC', 'TATCGCTA', 'CTATCGCT']\n"
     ]
    }
   ],
   "source": [
    "print(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect solution TTTACAAG CGGACTCT\n",
      "Incorrect solution CCGCTATC CGACTGTC\n",
      "Incorrect solution TCGGACTC CGCAAACC\n",
      "Incorrect solution CCGACTGT CCGCCCTT\n",
      "Incorrect solution GCAATGTT TACGCCAA\n",
      "Incorrect solution TGCTATCG TGGTGCCG\n",
      "Incorrect solution GCCGCCCT ATCGCTAC\n",
      "Incorrect solution CTGGTGCC ATCGCAAA\n",
      "Incorrect solution TCGCAAAC TATCGCTA\n",
      "Incorrect solution TATCGCTA CTATCGCT\n"
     ]
    }
   ],
   "source": [
    "# is this a correct solution?\n",
    "for i in range(0, (len(solution)-1)):\n",
    "    suffix_curr = solution[i][1:]\n",
    "    prefix_nxt = solution[i+1][:7]\n",
    "    if suffix_curr != prefix_nxt:\n",
    "        print(\"Incorrect solution\", solution[i], solution[i+1])"
=======
   "execution_count": null,
   "id": "3adc8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# did we actually hit all nodes?\n",
    "for i in sol_test:\n",
    "    for j in range(len(sol_test))"
>>>>>>> c6131b68554da3e3253e3b08cf7e9527d21ea320:et4xam_aln4t-updates.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print assembled sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to properly visualize graphs\n",
    "%load_ext gvmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to visualize de Bruijn graphs\n",
    "%dotstr utils.viz_debruijn(nodes_bruijn, edges_bruijn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main assembly algorithm\n",
    "\n",
    "def assemble_sequence(nodes, edges):\n",
    "    assembled_sequence = \"\"\n",
    "    # Your code here\n",
    "    return assembled_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output assembled sequence\n",
    "\n",
    "assmebled_seq = assemble_sequence(nodes, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Sequencing SARS-CoV-2 virus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on from TeleTubbies to real-world organisms. Let's start small- with a variant of the SARS-CoV-2 virus. You're given reads from <i>actual</i> genome sequencing runs in the SARS-CoV2.fastq file provided.\n",
    "\n",
    "Repeat Question 1.3 on this data. You can re-use your implementation and simply run it on the new data. Print out your reconstructed sequence to a file \"output.txt\". For this part, we will still assume that all the reads are error-free. Set $k=25$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sequence reads\n",
    "sequence_reads_covid, qualities_covid = utils.read_fastq('SARS-CoV2.fastq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read reads into graph\n",
    "nodes_covid, edges_covid = build_graph(sequence_reads_covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call main assembly algorithm\n",
    "assmebled_covid_seq = assemble_sequence(nodes_covid, edges_covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write assembled sequence to file\n",
    "\n",
    "assmebled_seq = \"\" # Use your assembled genome\n",
    "with open(\"covid_overlap.txt\", \"w\") as f:\n",
    "    f.write(assmebled_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3- Error-Aware Assembly (Extra Credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the parts above, we assumed error-free reads while assembling $k$-mers. As much as we'd like that, actual reads can (and do) have errors, captured by their Phred scores. For this question, you're given raw, actual reads from sequencing runs (download reads here: https://sra-pub-sars-cov2.s3.amazonaws.com/sra-src/SRR11528307/ABS2-LN-R1_cleaned_paired.fastq.gz).  Given these reads and their Phred33 scores, can you assemble the genome?\n",
    "\n",
    "<b>Print out your assembled sequence, along with a brief explanation of how your algorithm works</b>\n",
    "\n",
    "This is an open-ended question. You are free to use any approach to deal with the issue. Make sure you provide your code, along with any assumptions you may have, in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
